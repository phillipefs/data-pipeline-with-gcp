name: 'Deploy Python File to GCP Bucket'

on:
  push:
    branches:
    - master
    paths:
      - 'etl-spark/main.py'
  pull_request:
    branches:
    - master
    paths:
      - 'etl-spark/main.py'

jobs:
  deploy_script:
    name: 'Deploy Script'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Authorize GCP
        uses: 'google-github-actions/auth@v2'
        with:
          credentials_json:  ${{ secrets.GOOGLE_CREDENTIALS }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          version: '>= 363.0.0'
          project_id: 'datapipelines-419810'

      - name: Configure Docker
        run: |-
          gcloud auth configure-docker

      - name: Deploy
        run: gsutil cp etl-spark/main.py gs://data-pipeline-combustiveis-br-pyspark-code/
