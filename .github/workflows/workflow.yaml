name: 'WORKFLOW CI/CD'

on:
  push:
    branches:
      - master
    paths:
      - '**.tf'
      - 'etl-spark/main.py'

  pull_request:
    branches:
      - master
    paths:
      - '**.tf'

jobs:

  changes:
    runs-on: ubuntu-latest
    outputs:
      job_spark: ${{ steps.changes.outputs.job_spark }}
      infra: ${{ steps.changes.outputs.infra }}
    steps:
    - uses: actions/checkout@v3
    - uses: dorny/paths-filter@v2
      id: changes
      with:
        filters: |
          job_spark:
            - 'etl-spark/main.py'
          infra:
            - '**.tf' 

  deploy_script:
    needs: changes
    name: 'Deploy Script'
    if: github.event_name == 'push' && github.ref == 'refs/heads/master' && ${{ needs.changes.outputs.job_spark == 'true' }}
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3
        with:
            fetch-depth: 0

      - name: Base SHA
        id: base-sha
        run: echo "sha=$(git rev-parse origin/master)" >> $GITHUB_OUTPUT
      
      - name: Get Changed Directories
        id: changed-directories
        uses: tj-actions/changed-files@v35
        with:
            base_sha: "${{ steps.base-sha.outputs.sha }}"
      
      - name: List all changed files
        run: |
          for file in ${{ steps.changed-directories.outputs.all_changed_and_modified_files }}; do
            echo $file
          done
          
      - name: Checkout
        uses: actions/checkout@v2

      - name: List Modified Files
        run: |
          echo "Modified Files:"
          echo "${{ github.event.head_commit.modified }}"

      - name: Authorize GCP
        uses: 'google-github-actions/auth@v2'
        with:
          credentials_json:  ${{ secrets.GOOGLE_CREDENTIALS }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          version: '>= 363.0.0'
          project_id: 'datapipelines-419810'

      - name: Configure Docker
        run: |-
          gcloud auth configure-docker

      - name: Deploy
        run: gsutil cp etl-spark/main.py gs://data-pipeline-combustiveis-br-pyspark-code/

  terraform:
    needs: changes
    if: ${{ needs.changes.outputs.infra == 'true' }}
    name: 'Terraform'
    runs-on: ubuntu-latest

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1

    - name: Print Event Path
      run: |
          echo "Files Changed: ${{ github.event.head_commit.modified }}"


    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init
      env:
        GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan -lock=false
      env:
        GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
      env:
        GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }} 