name: 'WORKFLOW CI/CD'

on:
  push:
    branches:
      - master
    paths:
      - '**.tf'
      - 'etl-spark/**.py'

  pull_request:
    branches:
      - master
    paths:
      - '**.tf'

jobs:
  changes:
    runs-on: ubuntu-latest
    outputs:
      job_spark: ${{ steps.changes.outputs.job_spark }}
      infra: ${{ steps.changes.outputs.infra }}
    steps:
    - uses: actions/checkout@v3
    - uses: dorny/paths-filter@v2
      id: changes
      with:
        filters: |
          job_spark:
            - 'etl-spark/**.py'
          infra:
            - '**.tf' 

  deploy_spark_files:
    needs: changes
    name: 'Deploy Spark Files'
    if: github.event_name == 'push' && github.ref == 'refs/heads/master' && ${{ needs.changes.outputs.job_spark == 'true' }}
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Get changed Spark Files
        id: changed-spark-files
        # To compare changes between the current commit and the last pushed remote commit set `since_last_remote_commit: true`. e.g
        # with:
        #   since_last_remote_commit: true 

        uses: tj-actions/changed-files@v44
        with:
        # Avoid using single or double quotes for multiline patterns
          files: |
            etl-spark/**

      - name: Listing ALL changed Spark files
        env:
          ALL_CHANGED_FILES: ${{ steps.changed-spark-files.outputs.all_changed_files }}
        run: |
          for file in ${ALL_CHANGED_FILES}; do
            echo "$file was changed"
          done

      - name: List deleted files
        run: |
          deleted_files=$(git diff --diff-filter=D --name-only ${{ github.event.before }} ${{ github.sha }} | grep "^etl-spark/") || true
          if [ -n "$deleted_files" ]; then
            for file in $deleted_files; do
              echo "$file was deleted"
            done
          else
            echo "No files were deleted"
          fi
         
      - name: Authorize GCP
        uses: 'google-github-actions/auth@v2'
        with:
          credentials_json:  ${{ secrets.GOOGLE_CREDENTIALS }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          version: '>= 363.0.0'
          project_id: 'datapipelines-419810'

      - name: Configure Docker
        run: |-
          gcloud auth configure-docker

      - name: Deploy Spark Files
        env:
          ALL_CHANGED_FILES: ${{ steps.changed-spark-files.outputs.all_changed_files }}
        run: |
          for file in ${ALL_CHANGED_FILES}; do          
            echo "Copying file $file ...."
            gsutil cp $file gs://data-pipeline-combustiveis-br-pyspark-code/
          done

      - name: Removing Old SPark Files
        run: |
          deleted_files=$(git diff --diff-filter=D --name-only ${{ github.event.before }} ${{ github.sha }} | grep "^etl-spark/") || true
          if [ -n "$deleted_files" ]; then
            for file in $deleted_files; do
              filename=$(basename "$file")
              echo "Removing File: $filename ..."
              gsutil rm -r -f gs://data-pipeline-combustiveis-br-pyspark-code/$filename
            done
          else
            echo "No files were deleted"
          fi

  terraform:
    needs: changes
    if: ${{ needs.changes.outputs.infra == 'true' }}
    name: 'Terraform'
    runs-on: ubuntu-latest

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init
      env:
        GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan -lock=false
      env:
        GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
      env:
        GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }} 